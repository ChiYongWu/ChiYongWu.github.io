<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chiyongwu.github.io</id>
    <title>SwordPal&apos;s blog</title>
    <updated>2021-05-15T23:15:06.285Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chiyongwu.github.io"/>
    <link rel="self" href="https://chiyongwu.github.io/atom.xml"/>
    <subtitle>等候未来的你</subtitle>
    <logo>https://chiyongwu.github.io/images/avatar.png</logo>
    <icon>https://chiyongwu.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, SwordPal&apos;s blog</rights>
    <entry>
        <title type="html"><![CDATA[常用的linux命令]]></title>
        <id>https://chiyongwu.github.io/post/chang-yong-de-linux-ming-ling/</id>
        <link href="https://chiyongwu.github.io/post/chang-yong-de-linux-ming-ling/">
        </link>
        <updated>2021-03-27T12:57:00.000Z</updated>
        <content type="html"><![CDATA[<h3 id="目录类">目录类</h3>
<p>/ 代表根目录<br>
. 代表当前目录<br>
.. 代表上级目录<br>
cd / 进入根目录<br>
cd .. 进入上级目录<br>
ls 查看当前目录下的所有文件<br>
ll 查看当前目录下所有文件的详细信息<br>
pwd 显示当前目录的完整路径</p>
<h3 id="文件操作类">文件操作类</h3>
<p>cp /home/a.txt ./b.txt 将/home目录下的a.txt复制到当前目录并命名为b.txt<br>
cp -r /home/test1 /root/test2 将home目录下的test1文件夹，复制到root目录下，并命名为test2<br>
mv ./a.txt /home/b.txt 将当前目录下的a.txt移动到home目录下，并命名为b.txt<br>
rm -rf ./a.txt 删除当前目录下的a.txt<br>
mkdir test 在当前目录下创建一个test文件夹<br>
mkdir -p /home/servers/test：在/home/servers目录下创建一个test文件夹，如果父目录不存在，则一并创建<br>
touch a.txt 在当前目录下创建一个文件a.txt<br>
scp -rp ./a.txt root@192.168.1.119:/home/test ：将当前目录下的a.txt复制到1.119机器上的/home/test目录下<br>
./xxx.sh：执行当前目录下的xxx.sh文件</p>
<h3 id="文件工具类">文件工具类</h3>
<p>vi ./a.txt：编辑a.txt文件<br>
按i进入编辑模式，可以移动光标进行文本编辑操作<br>
按esc退出编辑模式</p>
<pre><code>在非编辑模式下：
按ctrl+f：向前翻一页
按ctrl+b：向后翻一页
按ctrl+d：向前翻半页
按ctrl+u：向后翻半页
按G：移动光标到文件最后
按0：移动光标到文件最开始
按$：移动光标到行尾
按^：移动光标到行首
yy：复制光标当前行到缓冲区
p：粘贴复制的内容
dd：删除光标当前行
输入/abc回车 搜索文件中包含abc的内容
输入:wq 保存文件并退出
</code></pre>
<p>cat ./a.txt：一次性读取并打印a.txt文件里的所有信息<br>
more ./a.txt：读取a.txt文件，每次读取一屏，按空格键翻页<br>
tail -200 a.txt 读取a.txt文件的后两百行<br>
tail -f a.txt 实时读取a.txt文件<br>
head -10 a.txt：读取a.txt文件的前10行</p>
<h3 id="文件压缩解压">文件压缩/解压</h3>
<p>zip -r test.zip test ：将当前目test文件夹压缩为test.zip<br>
unzip test.zip ： 将test.zip解压到当前目录<br>
tar cvf test.tar.gz test ：将test文件夹压缩为test.tar.gz<br>
tar xvf test.tar.gz ：将test.tar.gz包解压到当前目录<br>
unzip test.war ：将test.war解压到当前目录</p>
<h3 id="搜索类">搜索类</h3>
<p>find / -name a.txt ：从根目录下全局搜索a.txt文件<br>
grep &quot;error&quot; test.log ：从test.log中过滤出包含error的文本行</p>
<h3 id="权限类">权限类</h3>
<p>chmod +x ./a.txt ：对当前目录下的a.txt添加可执行权限<br>
chmod +x ./* ：对当前目录下所有文件添加可执行权限<br>
chmod 777 ./a.txt：对a.txt文件设置所有人均有读/写/执行权限<br>
chown root:root ./<em>：将当前所有目录文件的拥有者改为root组的root用户<br>
chown -R root:root ./</em> 将当前所有目录和子目录文件的拥有者改为root组的root用户</p>
<h3 id="系统类">系统类</h3>
<p>ifconfig：查看系统ip信息（CentOS6.x）<br>
service network restart/start/stop：网卡重启/启动/关闭（CentOS6.x）<br>
service iptables stop/status/start 防火墙关闭|查看状态|开启（CentOS6.x）</p>
<p>ip addr：查看系统ip信息（CentOS7.x）<br>
systemctl restart/start/stop network：网卡重启/启动/关闭（CentOS7.x）<br>
systemctl stop/start/status firewalld.service： 防火墙关闭|查看状态|开启（CentOS7.x）</p>
<p>ps -ef|grep jmeter：查看系统里与jmeter相关的进程<br>
history | grep xxx ：查看linux命令执行历史，并过滤出包含xxx的命令<br>
nohup ./xxx.sh &amp;：在后台执行xxx.sh脚本<br>
netstat -anp | grep 8080 查看系统中8080端口建立的连接和所属进程</p>
<h3 id="性能监控类">性能监控类</h3>
<p>top：监控CPU、内存、进程<br>
free -m ：监控操作系统内存（MB）<br>
iostat -x -k 1：展示磁盘性能信息（kb）<br>
df -h：查看磁盘空间使用<br>
vmstat：综合性能监控<br>
netstat -anp | grep 8080：查看8080端口的连接</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux下Jmeter环境配置]]></title>
        <id>https://chiyongwu.github.io/post/linux-xia-jmeter-huan-jing-pei-zhi/</id>
        <link href="https://chiyongwu.github.io/post/linux-xia-jmeter-huan-jing-pei-zhi/">
        </link>
        <updated>2021-03-26T02:43:59.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>上传jdk-8u221-linux-x64.tar.gz 到Linux的/usr/local目录下</li>
<li>解压：tar xvf jdk-8u221-linux-x64.tar.gz</li>
<li>修改配置文件：vim /etc/profile</li>
<li>光标移动到最后一行，添加以下配置：</li>
</ol>
<pre><code>export JAVA_HOME=/usr/local/jdk1.8.0_221
export PATH=$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/WuChiYong/markdown_picture/raw/master/img/20210326104552.png" alt="image-20210326104552023" loading="lazy"></figure>
<ol start="5">
<li>退出vim，执行命令source /etc/profile，让配置生效</li>
<li>执行java -version命令验证</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cookie安全]]></title>
        <id>https://chiyongwu.github.io/post/cookie-an-quan/</id>
        <link href="https://chiyongwu.github.io/post/cookie-an-quan/">
        </link>
        <updated>2021-03-17T03:32:42.000Z</updated>
        <content type="html"><![CDATA[<p>Cookie特性：域名、路径、过期时间、http-only、secure、Same-Site</p>
<ul>
<li>
<p>域名：Cookie生效的域名</p>
</li>
<li>
<p>路径：Cookie生效的具体路径</p>
</li>
<li>
<p>http-only：Cookie只可被http、https协议读写，JavaScript代码无法读写Cookie，从而降低了Xss的风险。</p>
</li>
<li>
<p>secure：当设置为true时，表示创建的 Cookie 会被以安全的形式向服务器传输，也就是只能在 HTTPS 连接中被浏览器传递到服务器端进行会话验证，如果是 HTTP 连接则不会传递该信息，所以不会被窃取到Cookie 的具体内容。</p>
</li>
<li>
<p>SameSite：用来限制第三方 Cookie，从而减少安全风险。</p>
<p>关于SameSite的参考资料：http://www.ruanyifeng.com/blog/2019/09/cookie-samesite.html</p>
</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/WuChiYong/markdown_picture/raw/master/img/20210317095408.png" alt="image-20210317095407842" loading="lazy"></figure>
<p> 在浏览器中查看到的Cookie，满足域名、路径都符合当前页面路径下，不满足这两个条件的Cookie是不会显示在当前页面。</p>
<p>Cookie的增删改查</p>
<ul>
<li>增/查：document.cookie</li>
<li>删：设置Cookie的过期时间</li>
</ul>
<p>Cookie作用</p>
<ul>
<li>存储个性化设置</li>
<li>存储未登录时用户唯一标识</li>
<li>存储已登录用户的凭证</li>
<li>存储其他业务数据：比如某一个业务拉取之后缓存到Cookie，下次访问时直接走缓存。</li>
</ul>
<p>Cookie安全案例</p>
<p> 某学校教务系统使用了开源CMS，该CMS使用username作为唯一标识，该CMS文章作者暴露了username，可篡改成任意已有的username，如admin登录后台。</p>
<p>Cookie安全策略</p>
<ul>
<li>签名防篡改</li>
<li>私有变换（加密）</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[基于timestamp和nonce的防重放攻击]]></title>
        <id>https://chiyongwu.github.io/post/ji-yu-timestamp-he-nonce-de-fang-chong-fang-gong-ji/</id>
        <link href="https://chiyongwu.github.io/post/ji-yu-timestamp-he-nonce-de-fang-chong-fang-gong-ji/">
        </link>
        <updated>2021-03-09T15:33:57.000Z</updated>
        <content type="html"><![CDATA[<h3 id="基于timestamp和nonce的防重放攻击">基于timestamp和nonce的防重放攻击</h3>
<p> 以前总是通过timestamp来防止重放攻击，但是这样并不能保证每次请求都是一次性的。今天看到了一篇文章介绍的通过nonce（Number used once）来保证一次有效，感觉两者结合一下，就能达到一个非常好的效果了。</p>
<pre><code>  重放攻击是计算机世界黑客常用的攻击方式之一，所谓重放攻击就是攻击者发送一个目的主机已接收过的包，来达到欺骗系统的目的，主要用于身份认证过程。
</code></pre>
<p> 首先要明确一个事情，重放攻击是二次请求，黑客通过抓包获取到了请求的HTTP报文，然后黑客自己编写了一个类似的HTTP请求，发送给服务器。也就是说服务器处理了两个请求，先处理了正常的HTTP请求，然后又处理了黑客发送的篡改过的HTTP请求。</p>
<h4 id="1-基于timestamp的方案">1. 基于timestamp的方案</h4>
<p> 每次HTTP请求，都需要加上timestamp参数，然后把timestamp和其他参数一起进行数字签名。因为一次正常的HTTP请求，从发出到达服务器一般都不会超过60s，所以服务器收到HTTP请求之后，首先判断时间戳参数与当前时间相比较，是否超过了60s，如果超过了则认为是非法的请求。</p>
<p> 假如黑客通过抓包得到了我们的请求url： http://koastal.site/index/Info?uid=ZX07&amp;stime=1480862753&amp;sign=80b886d71449cb33355d017893720666</p>
<pre><code class="language-javascript">$sign=md5($uid.$token.$stime);
// 服务器通过uid从数据库中可读出token
</code></pre>
<p> 一般情况下，黑客从抓包重放请求耗时远远超过了60s，所以此时请求中的stime参数已经失效了。<br>
如果黑客修改stime参数为当前的时间戳，则sign参数对应的数字签名就会失效，因为黑客不知道token值，没有办法生成新的数字签名。但这种方式的漏洞也是显而易见的，如果在60s之后进行重放攻击，那就没办法了，所以这种方式不能保证请求仅一次有效。</p>
<h4 id="2-基于nonce的方案">2. 基于nonce的方案</h4>
<p> nonce的意思是仅一次有效的随机字符串，要求每次请求时，该参数要保证不同，所以该参数一般与时间戳有关，我们这里为了方便起见，直接使用时间戳的16进制，实际使用时可以加上客户端的ip地址，mac地址等信息做个哈希之后，作为nonce参数。<br>
 我们将每次请求的nonce参数存储到一个“集合”中，可以json格式存储到<a href="http://lib.csdn.net/base/mysql">数据库</a>或缓存中。<br>
 每次处理HTTP请求时，首先判断该请求的nonce参数是否在该“集合”中，如果存在则认为是非法请求。</p>
<p> 假如黑客通过抓包得到了我们的请求url： http://koastal.site/index/Info?uid=ZX07&amp;nonce=58442c21&amp;sign=80b886d71449cb33355d017893720666</p>
<pre><code class="language-javascript">$sign=md5($uid.$token.$nonce);
// 服务器通过uid从数据库中可读出token
</code></pre>
<p> nonce参数在首次请求时，已经被存储到了服务器上的“集合”中，再次发送请求会被识别并拒绝。<br>
 nonce参数作为数字签名的一部分，是无法篡改的，因为黑客不清楚token，所以不能生成新的sign。</p>
<p> 这种方式也有很大的问题，那就是存储nonce参数的“集合”会越来越大，验证nonce是否存在“集合”中的耗时会越来越长。我们不能让nonce“集合”无限大，所以需要定期清理该“集合”，但是一旦该“集合”被清理，我们就无法验证被清理了的nonce参数了。也就是说，假设该“集合”平均1天清理一次的话，我们抓取到的该url，虽然当时无法进行重放攻击，但是我们还是可以每隔一天进行一次重放攻击的。而且存储24小时内，所有请求的“nonce”参数，也是一笔不小的开销。</p>
<h4 id="3-基于timestamp和nonce的方案">3. 基于timestamp和nonce的方案</h4>
<p> 那我们如果同时使用timestamp和nonce参数呢？<br>
 nonce的一次性可以解决timestamp参数60s的问题，timestamp可以解决nonce参数“集合”越来越大的问题。<br>
 我们在timestamp方案的基础上，加上nonce参数，因为timstamp参数对于超过60s的请求，都认为非法请求，所以我们只需要存储60s的nonce参数的“集合”即可。</p>
<p> 假如黑客通过抓包得到了我们的请求url： http://koastal.site/index/Info?uid=ZX07&amp;stime=1480862753&amp;nonce=58442c21&amp;sign=80b886d71449cb33355d017893720666</p>
<p>其中：</p>
<pre><code class="language-javascript">$sign=md5($uid.$token.$stime.$nonce);
// 服务器通过uid从数据库中可读出token
</code></pre>
<p> 如果在60s内，重放该HTTP请求，因为nonce参数已经在首次请求的时候被记录在服务器的nonce参数“集合”中，所以会被判断为非法请求。超过60s之后，stime参数就会失效，此时因为黑客不清楚token的值，所以无法重新生成签名。</p>
<p> 综上，我们认为一次正常的HTTP请求发送不会超过60s，在60s之内的重放攻击可以由nonce参数保证，超过60s的重放攻击可以由stime参数保证。</p>
<p> 因为nonce参数只会在60s之内起作用，所以只需要保存60s之内的nonce参数即可。</p>
<p> 我们并不一定要每个60s去清理该nonce参数的集合，只需要在新的nonce到来时，判断nonce集合最后一次修改时间，超过60s的话，就清空该集合，存放新的nonce参数集合。其实nonce参数集合可以存放的时间更久一些，但是最少是60s。</p>
<p> 验证流程：</p>
<pre><code class="language-java">//判断stime参数是否有效
if( $now - $stime &gt; 60){
    die(&quot;请求超时&quot;);
}
//判断nonce参数是否在“集合”已存在
if( in_array($nonce,$nonceArray) ){
    die(&quot;请求仅一次有效&quot;);
}
//验证数字签名   
if ( $sign != md5($uid.$token.$stime.$nonce) ){
    die(&quot;数字签名验证失败&quot;);
}
//判断是否需要清理nonce集合
if( $now - $nonceArray-&gt;lastModifyTime &gt; 60 ){
    $nonceArray = null;
}
//记录本次请求的nonce参数
$nonceArray.push($nonce);
 
 
//开始处理合法的请求
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[解决Navicat Premium 15破解失败]]></title>
        <id>https://chiyongwu.github.io/post/jie-jue-navicat-premium-15-po-jie-shi-bai/</id>
        <link href="https://chiyongwu.github.io/post/jie-jue-navicat-premium-15-po-jie-shi-bai/">
        </link>
        <updated>2021-03-05T14:36:51.000Z</updated>
        <content type="html"><![CDATA[<p>问题：Navicat Premium 15破解时提示“rsa public key not find”</p>
<p>解决步骤：</p>
<ol>
<li>卸载Premium</li>
<li>删除：C:\Program Files\PremiumSoft\Navicat Premium 15</li>
<li>删除：C:\Users\用户名\Documents\Navicat</li>
<li>通过win+r，输入regedit打开注册表。找到：计算机\HKEY_CURRENT_USER\Software\PremiumSoft将PremiumSoft全部删除即可。</li>
<li>重新安装Premium，重新破解，问题解决。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PicGo+Gitee搭建个人图床]]></title>
        <id>https://chiyongwu.github.io/post/picgogitee-da-jian-ge-ren-tu-chuang/</id>
        <link href="https://chiyongwu.github.io/post/picgogitee-da-jian-ge-ren-tu-chuang/">
        </link>
        <updated>2021-02-07T03:35:35.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>下载安装PicGO：https://github.com/Molunerfinn/PicGo/releases</li>
<li>PicGO安装gitee插件：</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/WuChiYong/markdown_picture/raw/master/img/image-20210207112604882.png" alt="image-20210207112604882" loading="lazy"></figure>
<ol start="3">
<li>配置gitee插件：</li>
</ol>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/WuChiYong/markdown_picture/raw/master/img/image-20210207112851883.png" alt="image-20210207112851883" loading="lazy"></figure>
<ol start="4">
<li>配置typora：</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/WuChiYong/markdown_picture/raw/master/img/image-20210207113035757.png" alt="image-20210207113035757" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis（三）：Redis主从复制]]></title>
        <id>https://chiyongwu.github.io/post/redissan-redis-zhu-cong-fu-zhi/</id>
        <link href="https://chiyongwu.github.io/post/redissan-redis-zhu-cong-fu-zhi/">
        </link>
        <updated>2021-01-27T14:31:57.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-主从复制">一、主从复制</h2>
<p>主从复制：主节点负责写数据，从节点负责读数据，从而实现读写分离，提高redis的高可用性。</p>
<p>让一个服务器去复制（replicate）另一个服务器，我们称呼被复制的服务器为主节点（master），而对主服务器进行复制的服务器则被称为从节点（slave），</p>
<p>如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190624144921705-733401084.png" alt="img" loading="lazy"></figure>
<p>主从复制的特点：</p>
<p>1、一个master可以有多个slave</p>
<p>2、一个slave只能有一个master</p>
<p>3、数据流向是单向的，master到slave</p>
<p>主从复制的作用：</p>
<p>1、数据副本：多一份或多份数据拷贝，保证redis高可用</p>
<p>2、扩展性能：单机redis的性能是有限的，主从复制能横向扩展 如容量、QPS等</p>
<h2 id="二-主从复制实现方式">二、主从复制实现方式</h2>
<h3 id="客户端命令slaveof">客户端命令：slaveof</h3>
<figure data-type="image" tabindex="2"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190624151816311-1648676415.png" alt="img" loading="lazy"></figure>
<h3 id="配置方式">配置方式：</h3>
<p>新建redis-6380.conf，加入配置</p>
<pre><code># 1.指明谁是主节点
slaveof  your-master-ip  your-master-port

# 2.让从节点只做读的操作，保证主节点和从节点数据同步一致性和读写分离。
slave-ready-only yes
</code></pre>
<h2 id="三-全量复制和增量复制">三、全量复制和增量复制</h2>
<pre><code> 1. runId：Redis每次启动时，都会生成一个不同的id来标示当前运行的Redis。从节点中会保存主节点的run_id标示，如果主节点的Redis发生了重启，那么从节点依据ip和端口号连接到主节点时，就会发现主节点的run_id标示的改变（这种改变意味着主节点中的数据可能发生的大量的改动），所以此时就会引起全量复制，也就是将主节点中的所有数据全部复制过来。
root@f9eb2360ed36:/usr/local/bin# ./redis-cli -p 6379 info server
# Server
redis_version:4.0.14
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:9ac979c18029eef1
redis_mode:standalone
os:Linux 3.10.0-514.26.2.el7.x86_64 x86_64
arch_bits:64
multiplexing_api:epoll
atomicvar_api:atomic-builtin
gcc_version:6.3.0
process_id:1
run_id:49dbc223587cbdadd158adc21816979722b65ae1
tcp_port:6379
uptime_in_seconds:105535
uptime_in_days:1
hz:10
lru_clock:1086433
executable:/data/redis-server
config_file:

2. 偏移量：每当主节点增删改一个数据时，主节点中就会有一个数值来记录这种变化，偏移量就是记录Redis中数据改变的一个标示，当主节点更改一个数据时，偏移量也会发生对应的改变，而且主节点在将数据更改命令同步给从节点时，也会将该偏移量发送给从节点，这样就可以对比主从节点的偏移量，来观察是否出现主从不一致的问题。使用 ./redis-cli -p 6379 info replication 该命令即可在主节点中查看主从节点的偏移量
</code></pre>
<h3 id="31-全量复制">3.1  全量复制</h3>
<h4 id="过程">过程：</h4>
<ol>
<li>
<p>向主节点发送psync，有两个参数，第一个参数是runId，第二个参数是偏移量，第一次发送不知道主节点的runId，也不知道偏移量，因此从节点发送 ？ -1</p>
</li>
<li>
<p>主节点收到消息，根据？ -1 能判断出来是第一次复制，主节点把runId和offset 发送给Slave节点，</p>
</li>
<li>
<p>从节点保存主节点基本信息</p>
</li>
</ol>
<p>4-5-6. Master节点执行bgsave生成快照，在此期间会记录后续执行的数据更改命令所更改的数据，直到主节点将生成的RDB文件传输到从节点为止，</p>
<p>​      期间Master节点执行的写操作，主节点会将缓冲区中记录的新更改的数据发送给从节点</p>
<p>7-8   从节点清空此前的所有数据，加载RDB文件恢复数据并存入新更改的数据</p>
<figure data-type="image" tabindex="3"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190624163101212-1340503749.png" alt="img" loading="lazy"></figure>
<p>说明：</p>
<ul>
<li>全量复制的性能开销：1. bgsave生成RDB文件需要的时间，2. RDB文件在网络间的传输时间，3. 从节点的数据清空时间 ， 4. 加载RDB文件的时间 5. 可能的 AOF  重写时间</li>
<li>数据更改命令缓冲区repl_back_buffer用于：当Redis通过Linux中的fork()函数开辟一个子进程处理其他事务（比如主进程执行bgsave生成一个RDB文件时，或者主进程执行bgrewriteaof生成一个AOF文件时）， 而主进程（即处理客户端命令的进程）后续执行的一些数据更改命令会被暂时保存在该区域，而且该区域空间有限（配置文件中repl-backlog-size 1mb即可配置该处空间大小）</li>
</ul>
<h3 id="32-部分复制">3.2  部分复制</h3>
<p>部分复制解决的问题：在实际环境中，主节点与从节点之间可能会发生一些网络波动等情况，导致从节点与主节点之间的网络连接断开（主从节点的Redis均未关闭），如果重新连接上后，可以使用全量复制来重新进行一次主从节点数据同步，但是全量复制会带来一个性能开销的问题，而且从节点中可能有大量数据是主节点中没有更该过的，也就是不需要进行再次同步的数据，如果使用全量复制肯定是带来了一些不必要的浪费。所以，部分复制功能就是为了解决该问题的。</p>
<h4 id="过程-2">过程：</h4>
<ol>
<li>
<p>主从节点直接连接断开，</p>
</li>
<li>
<p>此时主节点继续执行的数据更改命令会被记录在一个缓冲区 repl_back_buffer 中</p>
</li>
<li>
<p>当从节点重新连接主节点时，</p>
</li>
<li>
<p>自动发出一条命令(psync offset run_id)，将从节点中存储的主节点的Redis运行时id和从节点中保存的偏移量发送给主节点</p>
</li>
<li>
<p>主节点接收从节点发送的偏移量和id，对比此时主节点的偏移量和接收的偏移量，如果两个偏移量之差大于repl_back_buffer中的数据，那么就表示在断开连接期间从节点已经丢失了超出规定数量的数据，此时就需要进行全量复制了，否则就进行部分复制</p>
</li>
<li>
<p>将主节点缓冲区中的数据同步更新到从节点中，这样就实现了部分数据的复制同步，降低了性能开销</p>
</li>
</ol>
<figure data-type="image" tabindex="4"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190624174156107-191597742.png" alt="img" loading="lazy"></figure>
<h2 id="四-主从节点的故障处理">四、主从节点的故障处理</h2>
<ol>
<li>故障发生时服务自动转移（自动故障转移）：即当某个节点发生故障导致停止服务时，该节点提供的服务会有另一个节点自动代替提供，这样就实现了一个高可用的效果</li>
<li>从节点故障：即如果某个从节点发生了故障，导致无法向在该节点上的客户端提供读服务，解决办法就是使该客户端转移到另一个可用从节点上，但是在转移时，应该考虑该从节点能承受几个客户端的压力</li>
<li>主节点故障：如果主节点发生故障，在使用主节点进行读写操作的客户端就无法使用了，而使用从节点只进行读操作的客户端还是可以继续使用的，解决办法就是从从节点中选一个节点更改为主节点，并且将原主节点的客户端连接到新的主节点上，然后通过该客户端将其他从节点连接到新的主节点中</li>
<li>主从复制确实可以解决故障问题，但是主从复制不能实现自动故障转移，其必须要通过一些手动操作，而且非常麻烦，所以要实现自动故障转移还需要另一个功能，Redis中提供了sentinel功能来实现自动故障转移。</li>
</ol>
<h2 id="五-主从节点的故障处理">五、主从节点的故障处理</h2>
<ol>
<li>读写分离：即客户端发来的读写命令分开，写命令交给主节点执行，读命令交给从节点执行，不仅减少了主节点的压力，而且增强了读操作的能力；但也会造成一些问题</li>
</ol>
<ul>
<li>但是主从节点之间数据复制造成的阻塞延迟也可能会导致主从不一致的情况，也就是主节点先进行了写操作，但可能因为数据复制造成的阻塞延迟，导致在从节点上进行的读操作获取的数据与主节点不一致</li>
<li>读取过期数据：主从复制会将带有过期时间的数据一并复制到从节点中，但是从节点是没有删除数据的能力的，即使是过期数据，所以主节点中的已经删除了过期数据，但是因为主从复制的阻塞延迟问题导致从节点中的过期数据没有删除，此时客户端就会读到一个过期数据</li>
</ul>
<ol start="2">
<li>主从配置不一致：造成的问题有</li>
</ol>
<ul>
<li>比如配置中的maxmemory参数如果配置不一致，比如主节点2Gb，从节点1Gb，那么就可能会导致数据丢失；以及一些其他配置问题</li>
</ul>
<ol start="3">
<li>规避全量复制：全量复制的性能开销较大，所以要尽量避免全量复制，</li>
</ol>
<ul>
<li>在第一次建立主从节点关系式一定会发生全量复制；可以适当减小Redis的maxmemory参数，这样可以使得RDB更快，或者选择在客户端操作低峰期进行，比如深夜</li>
<li>从节点中保存的主节点run_id不一致时也一定会发生全量复制（比如主节点的重启）；可以通过故障转移来尽量避免，例如Redis Sentinel 与 Redis Cluster</li>
<li>当主从节点的偏移量之差大于命令缓冲区repl_back_buffer中对应数据的偏移差时，也会发生全量复制，也就是上面的部分复制的复制过程中所说的；可以适当增大配置文件中repl-backlog-size即数据缓冲区可尽量避免</li>
</ul>
<ol start="4">
<li>规避复制风暴：</li>
</ol>
<ul>
<li>单主节点导致的复制风暴，即当主节点重启后，要向其所有的从节点都进行一次全量复制，这非常消耗性能；可以更换主从节点的拓扑结构，更换为类似树形的结构，一个主节点只与少量的从节点建立主从关系，而而这些主节点又与其他从节点构成主从关系，</li>
<li>如图所示<img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190624175939473-823111126.png" alt="img" loading="lazy"></li>
<li>单主节点机器复制风暴：即如果过一台机器专门用来部署多个主节点，然后其他机器部署从节点，那么一旦主节点机器宕机重启，就会引起所有的主从节点之间的全量复制，造成非常大的性能开销；可以采用多台机器，分散部署主节点，或者使用自动故障转移来将某个从节点变为主节点实现一个高可用</li>
</ul>
<p>感谢支持，感谢观看。</p>
<p>参考：https://my.oschina.net/ProgramerLife/blog/2254321</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis(二)：Redis持久化RDB和AOF]]></title>
        <id>https://chiyongwu.github.io/post/rediser-redis-chi-jiu-hua-rdb-he-aof/</id>
        <link href="https://chiyongwu.github.io/post/rediser-redis-chi-jiu-hua-rdb-he-aof/">
        </link>
        <updated>2021-01-27T14:31:17.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-redis两种持久化方式">一、Redis两种持久化方式</h2>
<p>对Redis而言，其数据是保存在内存中的，一旦机器宕机，内存中的数据会丢失，因此需要将数据异步持久化到硬盘中保存。这样，即使机器宕机，数据能从硬盘中恢复。</p>
<p>常见的数据持久化方式：</p>
<p>1.快照：类似拍照记录时光，快照是某时某刻将数据库的数据做拍照记录下其数据信息。如MYSQL的Dump，Redis的RDB模式</p>
<p>2.写日志方式：是将数据的操作全部写到日志当中，需要恢复的时候，按照日志记录的操作记录重新再执行一遍。例如MYSQL的Binlog，Redis的AAOF模式、</p>
<h2 id="二-rdb">二、RDB</h2>
<h3 id="说明">说明：</h3>
<p>redis默认开启，将redis在内存中保存的数据，以快照的方式持久化到硬盘中保存。</p>
<h3 id="触发机制">触发机制：</h3>
<p>1.save命令：阻塞方式，需要等redis执行完save后，才能执行其他get、set等操作。同步方式</p>
<p>2.bgsave命令：非阻塞，其原理是调用linux 的 fork()函数，创建redis的子进程，子进程进行创建 rdb 文件的操作。异步方式，</p>
<p>3.自动方式：在redis.conf文件中配置，如下 save &lt;指定时间间隔&gt; &lt;执行指定次数更新操作&gt; ，save 60 10000 表示 60秒年内有10000次操作会自动生成rdb文件。</p>
<pre><code># Save the DB on disk:
#
#   save &lt;seconds&gt; &lt;changes&gt;
#
#   Will save the DB if both the given number of seconds and the given
#   number of write operations against the DB occurred.
#
#   In the example below the behaviour will be to save:
#   after 900 sec (15 min) if at least 1 key changed
#   after 300 sec (5 min) if at least 10 keys changed
#   after 60 sec if at least 10000 keys changed
#
#   Note: you can disable saving at all commenting all the &quot;save&quot; lines.
#
#   It is also possible to remove all the previously configured save
#   points by adding a save directive with a single empty string argument
#   like in the following example:
#
#   save &quot;&quot;

save 900 1
save 300 10
save 60 10000
</code></pre>
<p>4.其他方式</p>
<ul>
<li>4.1 执行flushall命令，清空数据，几乎不用</li>
<li>4.2 执行shutdown命令，安全关闭redis不丢失数据，几乎用不到。</li>
<li>4.3 主从复制，在主从复制的时候，rdb文件作为媒介来关联主节点和从节点的数据一致。</li>
</ul>
<h3 id="最佳配置参考">最佳配置参考：</h3>
<pre><code>vim redis.conf
</code></pre>
<pre><code># 1. 将自动生成rdb文件注释掉
# save 900 1
# save 300 10
# save 60 10000

# The filename where to dump the DB
# 2. rdb的文件名，改为dump+ 端口.rbd
dbfilename dump-${port}.rdb


# Note that you must specify a directory here, not a file name.
# 3. 文件持久化目录，日志目录，改到分布式存储中或者放到较大的硬盘目录中。
dir /yourbigdata/

# 4. 在bgsave发生错误时停止写入
stop-writes-on-bgsave-error yes

# 5.采用压缩方式，不然生成的rdb文件可能巨大无比。压缩后主从复制拷贝文件小，速度也快。
rdbcompression yes

# 6.采用校验和
rdbchecksum yes
</code></pre>
<h2 id="rdb优缺点">RDB优缺点</h2>
<p>优点：<br>
1 适合大规模的数据恢复。<br>
2 如果业务对数据完整性和一致性要求不高，RDB是很好的选择。</p>
<p>缺点：<br>
1 不可控，容易丢失数据：数据的完整性和一致性不高，因为RDB可能在最后一次备份时宕机了。<br>
2 耗时耗性能：备份时占用内存，因为Redis 在备份时会独立创建一个子进程，将数据写入到一个临时文件（此时内存中的数据是原来的两倍哦），最后再将临时文件替换之前的备份文件。<br>
所以Redis 的持久化和数据的恢复要选择在夜深人静的时候执行是比较合理的。</p>
<h2 id="三-aof">三、AOF</h2>
<h3 id="说明-2">说明：</h3>
<p>redis默认不开启，采用日志的形式来记录每个<strong>写操作</strong>，并<strong>追加</strong>到 .aof 文件中。Redis 重启的会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作</p>
<h3 id="生成aof的三种策略">生成AOF的三种策略：</h3>
<figure data-type="image" tabindex="1"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190624101908354-208380668.png" alt="img" loading="lazy"></figure>
<ol>
<li>
<p>always : 每条命令都会刷新到缓冲区，把缓冲区fsync到硬盘，对硬盘IO压力大，一般sata盘只有几百TPS，如果redis的写入量非常大，那对硬盘的压力也横刀。</p>
</li>
<li>
<p>everysec: 每秒把缓冲区fsync 到硬盘，如果出现故障，会丢失1s（默认配置是1秒）的数据。一般使用这种。</p>
</li>
<li>
<p>no : 由操作系统来定什么时候fsync到硬盘中。 缺点：不可控</p>
</li>
</ol>
<h3 id="aof重写">AOF重写：</h3>
<p>把过期的，没有用的，重复的，可优化的命令简化为很小的aof文件。实际上是redis内存中的数据回溯成aof文件。</p>
<p>如下图所示：</p>
<figure data-type="image" tabindex="2"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190624103925241-63040943.png" alt="img" loading="lazy"></figure>
<p>作用：</p>
<p>1.减少硬盘占用量</p>
<p>2.加快恢复速度</p>
<h3 id="aof重写的实现方式">AOF重写的实现方式</h3>
<p>1.bgrewriteaof  命令 ： 从redis的主进程fork一个子进程生成包含当前redis内存数据的最小命令集、</p>
<p>2.AOF重写配置：</p>
<pre><code># 1. aof文件增长率
auto-aof-rewrite-percentage 100

# 2. aof文件重写需要的尺寸
auto-aof-rewrite-min-size 64mb
</code></pre>
<p>自动触发时机：（需要同时满足）</p>
<ul>
<li>当前的aof文件大小  &gt;  aof文件重写需要的尺寸</li>
<li>（aof当前文件大小 - 上次aof的文件大小）/ 上次aof文件大小 &gt; aof文件增长率</li>
</ul>
<h3 id="最佳配置参考-2">最佳配置参考：</h3>
<pre><code>vim redis.conf
</code></pre>
<pre><code># 1. 打开aof功能
appendonly yes

# 2. 重命名aof文件名,以端口号区分
appendfilename &quot;appendonly-${port}.aof&quot;

# 3. 使用everysec策略
appendfsync everysec
# 4. 文件持久化目录，日志目录，改到分布式存储中或者放到较大的硬盘目录中。
dir /yourbigdata/
# 5. 在aof重写的时候，不做aof的append（追加）操作，这里出于性能考虑
no-appendfsync-on-rewrite yes
</code></pre>
<h3 id="aof优缺点">AOF优缺点</h3>
<p>优点：</p>
<p>1.数据的完整性和一致性更高</p>
<p>缺点：</p>
<ol>
<li>
<p>因为AOF记录的内容多，文件会越来越大，数据恢复也会越来越慢。</p>
</li>
<li>
<p>AOF每秒fsync一次指令硬盘，如果硬盘IO慢，会阻塞父进程；风险是会丢失1秒多的数据；在Rewrite过程中，主进程把指令存到mem-buffer中，最后写盘时会阻塞主进程。</p>
</li>
</ol>
<h2 id="四-关于redis持久化方式rdb和aof的缺点">四、关于Redis持久化方式RDB和AOF的缺点</h2>
<p>原因是redis持久化方式的痛点，缺点比较明显。</p>
<p>1、RDB需要定时持久化，风险是可能会丢两次持久之间的数据，量可能很大。</p>
<p>2、AOF每秒fsync一次指令硬盘，如果硬盘IO慢，会阻塞父进程；风险是会丢失1秒多的数据；在Rewrite过程中，主进程把指令存到mem-buffer中，最后写盘时会阻塞主进程。</p>
<p>3、这两个缺点是个很大的痛点。为了解决这些痛点，GitHub的两位工程师 Bryana Knight 和 Miguel Fernández 日前写了一篇 文章 ，讲述了将持久数据从Redis迁出的经验：</p>
<p><a href="http://www.open-open.com/lib/view/open1487736984424.html"> http://www.open-open.com/lib/view/open1487736984424.html</a></p>
<h2 id="五-如何选择rdb和aof">五、如何选择RDB和AOF</h2>
<p>建议全都要。</p>
<p>1、对于我们应该选择RDB还是AOF，官方的建议是两个同时使用。这样可以提供更可靠的持久化方案。</p>
<p>在redis 4.0 之后，官方提供了混合持久化模式，具体如下</p>
<h3 id="持久化文件结构">持久化文件结构</h3>
<p>上半段RDB格式，后半段是AOF模式。<img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190626160208108-1516752611.png" alt="img" loading="lazy"></p>
<h3 id="如何配置">如何配置</h3>
<pre><code>vim redis.conf

aof-use-rdb-preamble yes   
</code></pre>
<p>之后重启redis，运行bgrewriteaof命令，重写appendonly.aof，之后在Redis数据同步的时候，可以先加载rdb的内容，然后再执行aof指令部分使Redis数据同步</p>
<h3 id="数据恢复过程">数据恢复过程</h3>
<p>加载AOF文件的入口为loadAppendOnlyFile，代码如下</p>
<pre><code>int loadAppendOnlyFile(char *filename) {
    ...
    /* Check if this AOF file has an RDB preamble. In that case we need to
     * load the RDB file and later continue loading the AOF tail. */
    char sig[5]; /* &quot;REDIS&quot; */
    if (fread(sig,1,5,fp) != 5 || memcmp(sig,&quot;REDIS&quot;,5) != 0) {
        /* No RDB preamble, seek back at 0 offset. */
        if (fseek(fp,0,SEEK_SET) == -1) goto readerr;
    } else {
        /* RDB preamble. Pass loading the RDB functions. */
        rio rdb;

        serverLog(LL_NOTICE,&quot;Reading RDB preamble from AOF file...&quot;);
        if (fseek(fp,0,SEEK_SET) == -1) goto readerr;
        rioInitWithFile(&amp;rdb,fp);
        if (rdbLoadRio(&amp;rdb,NULL) != C_OK) {
            serverLog(LL_WARNING,&quot;Error reading the RDB preamble of the AOF file, AOF loading aborted&quot;);
            goto readerr;
        } else {
            serverLog(LL_NOTICE,&quot;Reading the remaining AOF tail...&quot;);
        }
    }
    ...
}
</code></pre>
<ol>
<li>
<p>打开AOF文件之后首先读取5个字符如果是&quot;REDIS&quot; ，那么就说明这是一个混合持久化的AOF文件，执行rdbLoadRio() 函数，解析RDB格式，解析文件内容直至遇到RDB_OPCODE_EOF结束。</p>
</li>
<li>
<p>执行 loadAppendOnlyFile() 函数，解析 AOF格式，直到结束整个加载过程完成。</p>
</li>
</ol>
<p>说明：正确的RDB格式一定是以&quot;REDIS&quot;开头而纯AOF格式则一定以&quot;*&quot;开头此时就会进入rdbLoadRio函数来加载数据。</p>
<p>这样就实现了混合持久化，加载aof文件时候，实现了数据文件不太大，而且能保证数据不丢失，加载效率比纯aof文件高。</p>
<p>本文根据视频和博客归纳。</p>
<p>参考：<a href="https://coding.imooc.com/class/chapter/151.html#Anchor">redis</a>，</p>
<p>https://yq.aliyun.com/articles/193034</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis(一)：Redis五种数据结构]]></title>
        <id>https://chiyongwu.github.io/post/redisyi-redis-wu-chong-shu-ju-jie-gou/</id>
        <link href="https://chiyongwu.github.io/post/redisyi-redis-wu-chong-shu-ju-jie-gou/">
        </link>
        <updated>2021-01-27T14:30:30.000Z</updated>
        <content type="html"><![CDATA[<h2 id="redis五种数据结构如下">Redis五种数据结构如下：</h2>
<h3 id=""><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190621163930814-1395015700.png" alt="img" loading="lazy"></h3>
<p>对redis来说，所有的key（键）都是字符串。</p>
<h2 id="1string-字符串类型">1.String 字符串类型</h2>
<p>是redis中最基本的数据类型，一个key对应一个value。</p>
<p>String类型是二进制安全的，意思是 redis 的 string 可以包含任何数据。如数字，字符串，jpg图片或者序列化的对象。</p>
<p>使用：get 、 set 、 del 、 incr、 decr 等</p>
<pre><code>127.0.0.1:6379&gt; set hello world
OK
127.0.0.1:6379&gt; get hello
&quot;world&quot;
127.0.0.1:6379&gt; del hello
(integer) 1
127.0.0.1:6379&gt; get hello
(nil)
127.0.0.1:6379&gt; get counter
&quot;2&quot;
127.0.0.1:6379&gt; incr counter
(integer) 3
127.0.0.1:6379&gt; get counter
&quot;3&quot;
127.0.0.1:6379&gt; incrby counter 100
(integer) 103
127.0.0.1:6379&gt; get counter
&quot;103&quot;
127.0.0.1:6379&gt; decr counter
(integer) 102
127.0.0.1:6379&gt; get counter
&quot;102&quot;
</code></pre>
<p>实战场景：</p>
<p>1.缓存： 经典使用场景，把常用信息，字符串，图片或者视频等信息放到redis中，redis作为缓存层，mysql做持久化层，降低mysql的读写压力。</p>
<p>2.计数器：redis是单线程模型，一个命令执行完才会执行下一个，同时数据可以一步落地到其他的数据源。</p>
<p>3.session：常见方案spring session + redis实现session共享，</p>
<h2 id="2hash-哈希">2.Hash （哈希）</h2>
<p>是一个Mapmap，指值本身又是一种键值对结构，如 value={{field1,value1},......fieldN,valueN}}</p>
<figure data-type="image" tabindex="1"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190621232209365-1000366002.png" alt="img" loading="lazy"></figure>
<p>使用：所有hash的命令都是 h  开头的   hget 、hset 、 hdel 等</p>
<pre><code>127.0.0.1:6379&gt; hset user name1 hao
(integer) 1
127.0.0.1:6379&gt; hset user email1 hao@163.com
(integer) 1
127.0.0.1:6379&gt; hgetall user
1) &quot;name1&quot;
2) &quot;hao&quot;
3) &quot;email1&quot;
4) &quot;hao@163.com&quot;
127.0.0.1:6379&gt; hget user user
(nil)
127.0.0.1:6379&gt; hget user name1
&quot;hao&quot;
127.0.0.1:6379&gt; hset user name2 xiaohao
(integer) 1
127.0.0.1:6379&gt; hset user email2 xiaohao@163.com
(integer) 1
127.0.0.1:6379&gt; hgetall user
1) &quot;name1&quot;
2) &quot;hao&quot;
3) &quot;email1&quot;
4) &quot;hao@163.com&quot;
5) &quot;name2&quot;
6) &quot;xiaohao&quot;
7) &quot;email2&quot;
8) &quot;xiaohao@163.com&quot;
</code></pre>
<p>实战场景：</p>
<p>1.缓存： 能直观，相比string更节省空间，的维护缓存信息，如用户信息，视频信息等。</p>
<h2 id="3链表">3.链表</h2>
<p>List 说白了就是链表（redis 使用双端链表实现的 List），是有序的，value可以重复，可以通过下标取出对应的value值，左右两边都能进行插入和删除数据。</p>
<figure data-type="image" tabindex="2"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190621233618769-504231907.png" alt="img" loading="lazy"></figure>
<p>使用列表的技巧</p>
<ul>
<li>lpush+lpop=Stack(栈)</li>
<li>lpush+rpop=Queue（队列）</li>
<li>lpush+ltrim=Capped Collection（有限集合）</li>
<li>lpush+brpop=Message Queue（消息队列）</li>
</ul>
<p>使用：</p>
<pre><code>127.0.0.1:6379&gt; lpush mylist 1 2 ll ls mem
(integer) 5
127.0.0.1:6379&gt; lrange mylist 0 -1
1) &quot;mem&quot;
2) &quot;ls&quot;
3) &quot;ll&quot;
4) &quot;2&quot;
5) &quot;1&quot;
127.0.0.1:6379&gt;
</code></pre>
<p>实战场景：</p>
<p>1.timeline：例如微博的时间轴，有人发布微博，用lpush加入时间轴，展示新的列表信息。</p>
<h2 id="4set-集合">4.Set  集合</h2>
<p>集合类型也是用来保存多个字符串的元素，但和列表不同的是集合中 1. 不允许有重复的元素，2.集合中的元素是无序的，不能通过索引下标获取元素，3.支持集合间的操作，可以取多个集合取交集、并集、差集。</p>
<figure data-type="image" tabindex="3"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190622001013515-677922001.png" alt="img" loading="lazy"></figure>
<p>使用：命令都是以s开头的 sset 、srem、scard、smembers、sismember</p>
<pre><code>127.0.0.1:6379&gt; sadd myset hao hao1 xiaohao hao
(integer) 3
127.0.0.1:6379&gt; SMEMBERS myset
1) &quot;xiaohao&quot;
2) &quot;hao1&quot;
3) &quot;hao&quot;
127.0.0.1:6379&gt; SISMEMBER myset hao
(integer) 1
</code></pre>
<p>实战场景;</p>
<p>1.标签（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。</p>
<p>2.点赞，或点踩，收藏等，可以放到set中实现</p>
<h2 id="5zset-有序集合">5.zset 有序集合</h2>
<p>有序集合和集合有着必然的联系，保留了集合不能有重复成员的特性，区别是，有序集合中的元素是可以排序的，它给每个元素设置一个分数，作为排序的依据。</p>
<p>（有序集合中的元素不可以重复，但是score 分数 可以重复，就和一个班里的同学学号不能重复，但考试成绩可以相同）。</p>
<figure data-type="image" tabindex="4"><img src="https://img2018.cnblogs.com/blog/1289934/201906/1289934-20190622000959260-539243592.png" alt="img" loading="lazy"></figure>
<p>使用： 有序集合的命令都是 以 z 开头  zadd 、 zrange、 zscore</p>
<pre><code>127.0.0.1:6379&gt; zadd myscoreset 100 hao 90 xiaohao
(integer) 2
127.0.0.1:6379&gt; ZRANGE myscoreset 0 -1
1) &quot;xiaohao&quot;
2) &quot;hao&quot;
127.0.0.1:6379&gt; ZSCORE myscoreset hao
&quot;100&quot;
</code></pre>
<p>实战场景：</p>
<p>1.排行榜：有序集合经典使用场景。例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Babel]]></title>
        <id>https://chiyongwu.github.io/post/babel/</id>
        <link href="https://chiyongwu.github.io/post/babel/">
        </link>
        <updated>2021-01-24T03:55:51.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-简介">1. 简介</h2>
<p>ES6的某些高级语法在浏览器环境甚至是Node.js环境中无法执行。</p>
<p>Babel是一个广泛使用的转码器，可以将ES6代码转为ES5代码，从而在现有环境执行执行。</p>
<p>这意味着，你可以现在就用 ES6 编写程序，而不用担心现有环境是否支持。</p>
<h2 id="2-安装">2. 安装</h2>
<p>安装命令行转码工具</p>
<blockquote>
<p>Babel提供babel-cli工具，用于命令行转码。它的安装命令如下：</p>
</blockquote>
<pre><code class="language-javascript">npm install -g babel-cli
#查看是否安装成功
babel --version
</code></pre>
<h2 id="3-babel的使用">3. Babel的使用</h2>
<p>1、创建babel文件夹</p>
<p>2、初始化项目</p>
<pre><code>npm init -y
</code></pre>
<p>3、创建文件 src/example.js ，下面是一段ES6代码：</p>
<pre><code class="language-javascript">// 转码前
// 定义数据
let input = [1, 2, 3]
// 将数组的每个元素 +1
input = input.map(item =&gt; item + 1)
console.log(input)
</code></pre>
<p>4、配置 .babelrc</p>
<blockquote>
<p>Babel的配置文件是.babelrc，存放在项目的根目录下，该文件用来设置转码规则和插件，基本格式如下。</p>
</blockquote>
<pre><code>{
    &quot;presets&quot;: [],
    &quot;plugins&quot;: []
}
</code></pre>
<p>presets字段设定转码规则，将es2015规则加入 .babelrc：</p>
<pre><code>{
    &quot;presets&quot;: [&quot;es2015&quot;],
    &quot;plugins&quot;: []
}
</code></pre>
<p>5、安装转码器，在项目中安装</p>
<pre><code>npm install --save-dev babel-preset-es2015
</code></pre>
<p>6、转码</p>
<pre><code class="language-javascript"># npm install --save-dev csv-loader xml-loader
# 转码结果写入一个文件
mkdir dist1
# --out-file 或 -o 参数指定输出文件
babel src/example.js --out-file dist1/compiled.js
# 或者
babel src/example.js -o dist1/compiled.js
# 整个目录转码
mkdir dist2
# --out-dir 或 -d 参数指定输出目录
babel src --out-dir dist2
# 或者
babel src -d dist2
</code></pre>
<h2 id="4-自定义脚本">4. 自定义脚本</h2>
<p>1、改写package.json</p>
<pre><code>{
    // ...
    &quot;scripts&quot;: {
        // ...
        &quot;build&quot;:  &quot;babel src\\example.js -o dist\\compiled.js&quot;
    },
}
</code></pre>
<p>2、转码的时候，执行下面的命令</p>
<pre><code>mkdir dist
npm run build
</code></pre>
<p>参考资料：<br>
https://www.cnblogs.com/houjiao/p/12108060.html<br>
https://www.jiangruitao.com/babel/quick-start/</p>
]]></content>
    </entry>
</feed>